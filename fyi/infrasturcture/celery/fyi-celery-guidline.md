# Celery å¯¦ä½œæŒ‡å—

## ğŸ¯ Celery æ ¸å¿ƒç”¨é€”

### 1. **éåŒæ­¥ä»»å‹™è™•ç†**
Celery æ˜¯ä¸€å€‹åˆ†æ•£å¼ä»»å‹™ä½‡åˆ—ï¼Œä¸»è¦ç”¨æ–¼è™•ç†è€—æ™‚çš„æ“ä½œï¼Œé¿å…é˜»å¡ä¸»è¦çš„ Web è«‹æ±‚æµç¨‹ã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
- **Producerï¼ˆç”Ÿç”¢è€…ï¼‰**: ç™¼é€ä»»å‹™åˆ°ä½‡åˆ—
- **Brokerï¼ˆä»£ç†ï¼‰**: å„²å­˜ä»»å‹™çš„è¨Šæ¯ä½‡åˆ—ï¼ˆå¦‚ Redisã€RabbitMQï¼‰
- **Workerï¼ˆå·¥ä½œè€…ï¼‰**: åŸ·è¡Œä»»å‹™çš„é€²ç¨‹
- **Result Backendï¼ˆçµæœå¾Œç«¯ï¼‰**: å„²å­˜ä»»å‹™åŸ·è¡Œçµæœ

### 2. **åˆ†æ•£å¼ç³»çµ±æ¶æ§‹**
```python
# ä»»å‹™å®šç¾©
@shared_task
def process_large_data(data):
    # è€—æ™‚æ“ä½œ
    return processed_data

# ä»»å‹™èª¿ç”¨
task = process_large_data.delay(data)
result = task.get()  # åŒæ­¥ç­‰å¾…çµæœ
```

## ğŸ”„ èˆ‡è¨‚é–±è€…æ¨¡å¼çš„é—œä¿‚

### **è¨‚é–±è€…æ¨¡å¼åœ¨ Celery ä¸­çš„é«”ç¾**

#### 1. **äº‹ä»¶é©…å‹•æ¶æ§‹**
```python
# äº‹ä»¶ç™¼å¸ƒè€…ï¼ˆProducerï¼‰
@shared_task
def publish_user_registered_event(user_id):
    # ç™¼å¸ƒç”¨æˆ¶è¨»å†Šäº‹ä»¶
    send_task('notify_followers', args=[user_id])
    send_task('send_welcome_email', args=[user_id])
    send_task('update_recommendations', args=[user_id])

# äº‹ä»¶è¨‚é–±è€…ï¼ˆSubscribersï¼‰
@shared_task
def notify_followers(user_id):
    # é€šçŸ¥é—œæ³¨è€…
    pass

@shared_task
def send_welcome_email(user_id):
    # ç™¼é€æ­¡è¿éƒµä»¶
    pass
```

#### 2. **å¤šè¨‚é–±è€…æ¨¡å¼**
```python
# ä¸€å€‹äº‹ä»¶è§¸ç™¼å¤šå€‹è¨‚é–±è€…
@shared_task
def post_created_event(post_id):
    # ç™¼å¸ƒè²¼æ–‡å‰µå»ºäº‹ä»¶
    chain(
        update_user_stats.s(post_id),
        notify_followers.s(post_id),
        update_search_index.s(post_id),
        generate_recommendations.s(post_id)
    ).apply_async()
```

## ğŸš€ åœ¨ Threads å°ˆæ¡ˆä¸­çš„å¯¦ä½œå»ºè­°

### **ç¬¬ä¸€éšæ®µï¼šåŸºç¤ä»»å‹™è™•ç†**

#### 1. **AI äº‹å¯¦æŸ¥æ ¸éåŒæ­¥åŒ–**
```python
# tasks.py
@shared_task(bind=True, max_retries=3)
def fact_check_content(self, content_id, content_type, content_text):
    try:
        # èª¿ç”¨ OpenAI API
        result = openai_client.fact_check(content_text)
        
        # æ›´æ–°è³‡æ–™åº«
        update_fact_check_result(content_id, result)
        
        # ç™¼é€é€šçŸ¥
        notify_fact_check_complete.delay(content_id, result)
        
    except Exception as exc:
        # é‡è©¦æ©Ÿåˆ¶
        raise self.retry(exc=exc, countdown=60)

# views.py
def fact_check_post(request, post_id):
    post = get_post(post_id)
    fact_check_content.delay(post_id, "post", post.content)
    return Response({"message": "äº‹å¯¦æŸ¥æ ¸å·²é–‹å§‹è™•ç†"})
```

#### 2. **è¨ˆæ•¸å™¨æ‰¹é‡æ›´æ–°**
```python
@shared_task
def batch_update_counters():
    """å®šæœŸæ‰¹é‡æ›´æ–°è¨ˆæ•¸å™¨"""
    # æ›´æ–°è©•è«–è¨ˆæ•¸
    for key in redis_client.scan_iter(match="post:*"):
        post_id = key.decode().split(":", 1)[1]
        delta = int(redis_client.hget(key, "comments_count") or 0)
        if delta:
            Post.objects.filter(id=post_id).update(
                comments_count=F("comments_count") + delta
            )
            redis_client.hdel(key, "comments_count")
```

### **ç¬¬äºŒéšæ®µï¼šäº‹ä»¶é©…å‹•æ¶æ§‹**

#### 1. **ç”¨æˆ¶è¨»å†Šäº‹ä»¶**
```python
@shared_task
def user_registered_event(user_id):
    """ç”¨æˆ¶è¨»å†Šå¾Œè§¸ç™¼çš„äº‹ä»¶éˆ"""
    chain(
        send_welcome_email.s(user_id),
        create_default_follows.s(user_id),
        generate_initial_recommendations.s(user_id),
        update_user_statistics.s(user_id)
    ).apply_async()

# åœ¨ç”¨æˆ¶è¨»å†Šå¾Œèª¿ç”¨
def register_user(user_data):
    user = create_user(user_data)
    user_registered_event.delay(user.id)
    return user
```

#### 2. **è²¼æ–‡äº’å‹•äº‹ä»¶**
```python
@shared_task
def post_liked_event(post_id, user_id):
    """è²¼æ–‡è¢«æŒ‰è®šå¾Œçš„äº‹ä»¶è™•ç†"""
    group(
        update_post_stats.s(post_id),
        notify_post_author.s(post_id, user_id),
        update_user_recommendations.s(user_id),
        log_interaction.s("like", post_id, user_id)
    ).apply_async()
```

### **ç¬¬ä¸‰éšæ®µï¼šé€²éšåŠŸèƒ½**

#### 1. **åœ–ç‰‡è™•ç†ç®¡é“**
```python
@shared_task
def process_image_pipeline(image_id):
    """åœ–ç‰‡è™•ç†ç®¡é“"""
    chain(
        validate_image.s(image_id),
        compress_image.s(image_id),
        generate_thumbnails.s(image_id),
        update_image_metadata.s(image_id),
        notify_processing_complete.s(image_id)
    ).apply_async()
```

#### 2. **æœå°‹ç´¢å¼•æ›´æ–°**
```python
@shared_task
def update_search_index(content_id, content_type):
    """æ›´æ–°æœå°‹ç´¢å¼•"""
    content = get_content(content_id, content_type)
    
    # æ›´æ–° Elasticsearch
    es_client.index(
        index="content",
        id=content_id,
        body={
            "content": content.text,
            "author": content.author_name,
            "created_at": content.created_at,
            "type": content_type
        }
    )
```

## âš™ï¸ Celery é…ç½®å»ºè­°

### **settings.py é…ç½®**
```python
# Celery é…ç½®
CELERY_BROKER_URL = os.environ.get("CELERY_BROKER_URL", "redis://localhost:6379/0")
CELERY_RESULT_BACKEND = os.environ.get("CELERY_RESULT_BACKEND", "redis://localhost:6379/0")

# ä»»å‹™é…ç½®
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TIMEZONE = TIME_ZONE
CELERY_ENABLE_UTC = True

# é‡è©¦é…ç½®
CELERY_TASK_RETRY_DELAY = 60  # é‡è©¦é–“éš”
CELERY_TASK_MAX_RETRIES = 3   # æœ€å¤§é‡è©¦æ¬¡æ•¸

# ä»»å‹™è·¯ç”±
CELERY_TASK_ROUTES = {
    'threads.tasks.fact_check_content': {'queue': 'ai_queue'},
    'threads.tasks.process_image': {'queue': 'image_queue'},
    'threads.tasks.*': {'queue': 'default'},
}
```

### **Docker Compose é…ç½®**
```yaml
# docker-compose.yml
services:
  celery-worker:
    build: .
    command: celery -A core worker -l info
    volumes:
      - .:/app
    depends_on:
      - redis
      - postgres
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0

  celery-beat:
    build: .
    command: celery -A core beat -l info
    volumes:
      - .:/app
    depends_on:
      - redis
```

## ğŸ“Š ç›£æ§å’Œé™¤éŒ¯

### **ä»»å‹™ç›£æ§**
```python
# ä»»å‹™ç‹€æ…‹æª¢æŸ¥
def check_task_status(task_id):
    from celery.result import AsyncResult
    result = AsyncResult(task_id)
    return {
        "status": result.status,
        "result": result.result,
        "traceback": result.traceback
    }
```

### **éŒ¯èª¤è™•ç†**
```python
@shared_task(bind=True)
def robust_task(self, data):
    try:
        # ä»»å‹™é‚è¼¯
        return process_data(data)
    except Exception as exc:
        # è¨˜éŒ„éŒ¯èª¤
        logger.error(f"Task failed: {exc}")
        # é‡è©¦æˆ–ç™¼é€å‘Šè­¦
        if self.request.retries < 3:
            raise self.retry(countdown=60)
        else:
            send_alert.delay(f"Task {self.request.id} failed permanently")
```

## ğŸ¯ æœ€ä½³å¯¦è¸

1. **ä»»å‹™è¨­è¨ˆåŸå‰‡**
   - ä¿æŒä»»å‹™å°è€Œå°ˆæ³¨
   - é¿å…é•·æ™‚é–“é‹è¡Œçš„ä»»å‹™
   - ä½¿ç”¨é©ç•¶çš„é‡è©¦ç­–ç•¥

2. **éŒ¯èª¤è™•ç†**
   - å¯¦ç¾å®Œæ•´çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
   - ä½¿ç”¨æ­»ä¿¡ä½‡åˆ—è™•ç†å¤±æ•—ä»»å‹™
   - è¨˜éŒ„è©³ç´°çš„éŒ¯èª¤æ—¥èªŒ

3. **æ•ˆèƒ½å„ªåŒ–**
   - ä½¿ç”¨ä»»å‹™è·¯ç”±åˆ†é›¢ä¸åŒé¡å‹çš„ä»»å‹™
   - å¯¦ç¾ä»»å‹™å„ªå…ˆç´š
   - ç›£æ§ä½‡åˆ—é•·åº¦å’Œè™•ç†æ™‚é–“

4. **æ¸¬è©¦ç­–ç•¥**
   - ä½¿ç”¨ `CELERY_TASK_ALWAYS_EAGER` é€²è¡Œå–®å…ƒæ¸¬è©¦
   - å¯¦ç¾æ•´åˆæ¸¬è©¦é©—è­‰ä»»å‹™æµç¨‹
   - ä½¿ç”¨æ¨¡æ“¬å™¨æ¸¬è©¦éŒ¯èª¤æƒ…æ³
